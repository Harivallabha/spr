description: AWM

target:
  cluster: eu2
  vc: msrlabs

environment:
  image: philly/jobs/custom/pytorch:pytorch1.3.1-py36-cuda10.0
  registry: phillyregistry.azurecr.io


# azure storage configuration
storage:
  my_storage:
    # Replace with the name of the Azure Storage Account you created.
    #   If you followed the tutorial, this should be your_username
    storage_account_name: ankdefault
    # Specify a name of the container on your blob (ex. phillytools),
    #   to store data, results and code. It will be created if it does not exist.
    container_name: awmcontainer

# data
#   data upload is not required for this example

search:
  job_template:
    name: awm
    sku: G4
    command:
      - export PATH=$$PATH:~/.local/bin
      - export LC_ALL=C.UTF-8
      - export LANG=C.UTF-8
#      - git clone https://github.com/NVIDIA/apex
#      - cd apex
#      - pip install --user -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
#      - cd ..
      - pip install --user opencv-python wandb matplotlib scikit-learn 'gym[atari]' plotly recordclass pyprind psutil dill
      - pip install --user git+git://github.com/mila-iqia/atari-representation-learning.git
      - pip install --user git+git://github.com/astooke/rlpyt
      - wandb login fa235c4236ea0bd894bc3f26e87054a6ed6af293
      - python -m scripts.run_pizero --grayscale --game {game} {search-targets} --training-interval {training-interval} --batch-size-per-worker 200 {nce} {envs} --num-simulations 10 --total-env-steps 10000000 {reanalyze} --target-update-interval {uti} --savedir ./out --optim adam --multistep {multistep} --epoch-steps 10 --num-simulations 10 --c1 {c1} --evaluation-interval 80000 --visit-temp {visit-temp}  --discount 0.997  --num-trainers 4  --replay-ratio-upper {replay-ratio} --eval-simulations 25  --virtual-threads {virtual-threads}  --q-learning
  type: grid
  max_trials: 100
  params:
    - name: game
      spec: discrete
      values: ['ms_pacman']
    - name: nce
      spec: discrete
      values: ['--no-nce --value-loss-weight 0.1', '--no-nce --value-loss-weight 0.1 --prioritized']
    - name: envs
      spec: discrete
      values: ['--num-envs 64 --num-workers 1']
    - name: reanalyze
      spec: discrete
      values: ['']
    - name: uti
      spec: discrete
      values: [100]
    - name: multistep
      spec: discrete
      values: [10]
    - name: training-interval
      spec: discrete
      values: [64]
    - name: c1
      spec: discrete
      values: [1.25, 0.5, 1., 1.5]
    - name: search-targets
      spec: discrete
      values: ['']
    - name: visit-temp
      spec: discrete
      values: [1.0]
    - name: replay-ratio
      spec: discrete
      values: [-1]
    - name: virtual-threads
      spec: discrete
      values: [3]